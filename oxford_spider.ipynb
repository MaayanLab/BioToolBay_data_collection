{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "\n",
    "\n",
    "#IMPORTANT : remember to set the before_year (if you are interested in all articles published in 2013 and ealier before_year=2012)\n",
    "\n",
    "minimum_year=2013\n",
    "max_year=2017\n",
    "\n",
    "class JournalSpider(scrapy.Spider):\n",
    "    name=\"nar_spiderF\"\n",
    "    start_urls = [\n",
    "        'https://academic.oup.com/nar/issue',\n",
    "    ]\n",
    "\n",
    "    journal=\"Nucleic Acids Research\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        for url in self.start_urls:\n",
    "            yield scrapy.Request(url, self.parse, meta={'splash' : {'endpoint' : 'render.html', 'args' : { 'wait' : 5.5 }}})\n",
    "\n",
    "\n",
    "    def parse(self, response):\n",
    "        #Find avaiable years and store them in a dictionary of lists of avaiable years and their associated links\n",
    "        dict_dates={\n",
    "                'years' : response.xpath('//select[@id=\"YearsList\"]/option/text()').extract(),\n",
    "                'year_links' :response.xpath('//select[@id=\"YearsList\"]/option/@value').extract(),\n",
    "                }\n",
    "\n",
    "        i=-1#for iteration of lists inside the dictionary, it is incremented to 0 before the first use\n",
    "        for year in dict_dates['years']:\n",
    "            i=i+1\n",
    "            if int(year) >= minimum_year:\n",
    "                if int(year) <= max_year:\n",
    "                    next_year=\"https://academic.oup.com\"+dict_dates['year_links'][i]\n",
    "                    yield scrapy.Request(next_year, callback=self.parse_the_year, meta={'splash' : {'endpoint' : 'render.html', 'args' : { 'wait' : 5.0 }}})\n",
    "\n",
    "    def parse_the_issue(self, response):\n",
    "        for section in response.css('.section-container section'):\n",
    "            for article in section.css('.al-article-items'):\n",
    "                next_article=\"https://academic.oup.com\"+article.css('a::attr(href)').extract_first()\n",
    "                yield scrapy.Request(next_article, callback=self.parse_the_article, meta={'splash' : {'endpoint' : 'render.html', 'args' : { 'wait' : 3.5 }}})\n",
    "   \n",
    "\n",
    "    def parse_the_article(self,response):\n",
    "        article_abstract=response.css('.abstract')\n",
    "        article_whole=response.css('.widget-items')\n",
    "        images=response.css('img[alt*=\"Article has\"]::attr(alt)').extract_first()\n",
    "        all_links_list=[]\n",
    "        all_links=article_whole.css('a[href*=\"http\"]::attr(href)').extract()\n",
    "        link_altmetric=response.css('img[alt*=\"Article has\"]::attr(src)').extract_first()\n",
    "        references_class=response.css('.ref-list')\n",
    "        for link in all_links:\n",
    "            if len(link) < 80:\n",
    "                if re.search('doi|pubmed|scholar|new-image|creativecommons', link):\n",
    "                    pass\n",
    "                else:\n",
    "                    all_links_list.append(link)\n",
    "  \n",
    "        yield {\n",
    "            'link': response.url,\n",
    "            'doi' : response.css('.citation-doi a::attr(href)').extract_first(),\n",
    "            'altmetric_link': link_altmetric,\n",
    "            'abstract' : response.css('.abstract ::text').extract(),\n",
    "            'altmetric_score' : images,\n",
    "            'citations_link': response.css('.relatedArticleIn-content a::attr(href)').extract_first(),\n",
    "            'views': response.css('.artmet-number::text').extract_first(),\n",
    "            'citations_amount': response.css('.artmet-citations .artmet-number a::text').extract_first(),#works \n",
    "            'title': response.css('.widget-items h1 *::text').extract(),\n",
    "            'journal':  self.journal,\n",
    "            'authors': response.css('.linked-name ::text').extract(),\n",
    "            'tag': response.css('.article-metadata-tocSections a::text').extract_first(),\n",
    "            'topics': response.css('.related-topic-tag-list span::text').extract(),\n",
    "            'link_to_tools': article_abstract.css('a[href*=\"http\"]::attr(href)').extract(),\n",
    "            'all_links': all_links_list,\n",
    "            'references': [x.split('/')[-1] for x in references_class.css('.link-pub-id::attr(href)').extract()],\n",
    "            'date':response.css('.citation-date ::text').extract_first(),\n",
    "        }\n",
    "\n",
    "    def parse_the_year(self, response):\n",
    "        issues=response.xpath('//select[@id=\"IssuesList\"]/option/@value').extract()\n",
    "        for issue in issues:\n",
    "            next_issue=\"https://academic.oup.com\"+issue\n",
    "            yield scrapy.Request(next_issue, callback=self.parse_the_issue, meta={'splash' : {'endpoint' : 'render.html', 'args' : { 'wait' : 5.5 }}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
